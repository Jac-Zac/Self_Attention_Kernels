#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=112
#SBATCH --mem=10G
#SBATCH --partition=dcgp_usr_prod
#SBATCH --exclusive                 # Get exclusive access to benchmark
#SBATCH -A uTS25_Tornator_0
#SBATCH -t 00:02:00
#SBATCH --job-name=self_attention

# =======================================================
# Load the required modules for GCC and OpenMPI
module load openmpi/4.1.6--gcc--12.2.0

# 1. Load the specific VTune version
module load intel-oneapi-vtune/2024.1.0

# 2. Set the results directory name
# Good practice to include the version (v3) in the folder name
RESULT_DIR="vtune_report_v3"

# Set the executable name
EXEC=./cmhsa.out

# =======================================================
# Set OpenMP environment variables
export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}
export OMP_PLACES=cores
# export OMP_PROC_BIND=spread
export OMP_PROC_BIND=close
export OMP_DISPLAY_AFFINITY=TRUE

# Set the total number of MPI tasks
TOTAL_MPI_TASKS=${SLURM_NTASKS}

# Define the arguments for the executable
# A medium-sized grid suitable for a single-node run
ARGS="--batch 8 --n_heads 16 --seq_len 1024 --head_dim 64"

# Print run information
echo "Running on a single node with ${TOTAL_MPI_TASKS} MPI tasks."
echo "Each task uses ${OMP_NUM_THREADS} OpenMP threads."

# Minimal Python venv + requirements
# VENV_DIR="${VENV_DIR:-.venv}"
# PY_BIN="${PY_BIN:-$(command -v python3 || command -v python)}"
# if [ -z "$PY_BIN" ]; then
#   echo "Python not found. Load a Python module." >&2
#   exit 1
# fi
# [ -d "$VENV_DIR" ] || "$PY_BIN" -m venv "$VENV_DIR"
# # shellcheck disable=SC1090
# source "$VENV_DIR/bin/activate"
# python -m pip install --upgrade pip
#
# # Pick requirements.txt and install always
# REQ_FILE="${REQ_FILE:-$(git rev-parse --show-toplevel 2>/dev/null || pwd)/requirements.txt}"
# [ -f "$REQ_FILE" ] || REQ_FILE="requirements.txt"
# if [ -f "$REQ_FILE" ]; then
#   echo "Installing Python dependencies from $REQ_FILE..."
#   pip install -r "$REQ_FILE"
# else
#   echo "requirements.txt not found; skipping pip install."
# fi
#
# source .venv/bin/activate
#
# # Print run information
# echo "Running on a single node with ${TOTAL_MPI_TASKS} MPI tasks."
# echo "Each task uses ${OMP_NUM_THREADS} OpenMP threads."

# Compile and run the benchmark
# make benchmark

make multi DEBUG=1 VERSION=v3

# 3. Run Microarchitecture Exploration
# This tells you if your Attention kernel is "Retiring" instructions
# or stalled by memory/frontend issues.
vtune -collect uarch-exploration -result-dir ${RESULT_DIR}_uarch \
        ./cmhsa.out --batch 4 --n_heads 8 --seq_len 1024 --head_dim 64

# 3. Run Microarchitecture Exploration
# This tells you if your Attention kernel is "Retiring" instructions
# or stalled by memory/frontend issues.
# 4. (Optional) Run Memory Access analysis
# This will specifically pinpoint why you had that 87% cache miss rate earlier.
vtune -collect memory-access -result-dir ${RESULT_DIR}_mem \
        ./cmhsa.out --batch 4 --n_heads 8 --seq_len 1024 --head_dim 64

perf stat -d -d -e instructions,cycles,cache-references,cache-misses,dTLB-loads,dTLB-load-misses,iTLB-loads,iTLB-load-misses -a $EXEC $ARGS
