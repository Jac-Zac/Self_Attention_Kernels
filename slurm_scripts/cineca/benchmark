#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=112
#SBATCH --mem=10G
#SBATCH --partition=dcgp_usr_prod
#SBATCH --exclusive                 # Get exclusive access to benchmark
#SBATCH -A uTS25_Tornator_0
#SBATCH -t 00:10:00                 # 30 minutes for full scaling analysis
#SBATCH --job-name=self_attention_bench

# =======================================================
# Load the required modules
# module load openmpi/4.1.6--gcc--12.2.0

# Set the executable name
EXEC=./cmhsa.out

# =======================================================
# Set OpenMP environment variables
export OMP_PLACES=cores
export OMP_PROC_BIND=close
export OMP_DISPLAY_AFFINITY=TRUE

# Print run information
echo "Running scaling benchmark on Cineca"
echo "Available CPUs: ${SLURM_CPUS_PER_TASK}"

# =======================================================
# Minimal Python venv + requirements
VENV_DIR="${VENV_DIR:-.venv}"
PY_BIN="${PY_BIN:-$(command -v python3 || command -v python)}"
if [ -z "$PY_BIN" ]; then
  echo "Python not found. Load a Python module." >&2
  exit 1
fi
[ -d "$VENV_DIR" ] || "$PY_BIN" -m venv "$VENV_DIR"
# shellcheck disable=SC1090
source "$VENV_DIR/bin/activate"
python -m pip install --upgrade pip

# Pick requirements.txt and install
REQ_FILE="${REQ_FILE:-$(git rev-parse --show-toplevel 2>/dev/null || pwd)/requirements.txt}"
[ -f "$REQ_FILE" ] || REQ_FILE="requirements.txt"
if [ -f "$REQ_FILE" ]; then
  echo "Installing Python dependencies from $REQ_FILE..."
  pip install -r "$REQ_FILE"
else
  echo "requirements.txt not found; skipping pip install."
fi

source .venv/bin/activate

# =======================================================
# Create results directory
RESULTS_DIR="results"
mkdir -p "$RESULTS_DIR"

echo "=== Starting benchmark runs ==="
echo "Results will be saved to $RESULTS_DIR/"

# Thread counts to benchmark (scaled for 112 cores)
THREAD_COUNTS="1 2 4 8 16 28 56 112"

# Run benchmarks for each thread count, saving JSON output
for threads in $THREAD_COUNTS; do
  echo ""
  echo ">>> Running benchmark with $threads threads..."
  export OMP_NUM_THREADS=$threads
  make benchmark \
    BENCH_BACKEND=multi \
    BENCH_THREADS=$threads \
    USE_SRUN=1 \
    BENCH_OUTPUT_FILE="$RESULTS_DIR/benchmark_${threads}threads.json"
done

echo ""
echo "=== Merging benchmark results ==="

# Merge all JSON files into combined.json and delete individual files
python3 python_src/merge_results.py \
  "$RESULTS_DIR"/benchmark_*threads.json \
  --output "$RESULTS_DIR/combined.json" \
  --delete-inputs

echo ""
echo "=== Generating scaling plots ==="

# Generate scaling plots from combined results
python3 python_src/plotting/scaling_plot.py \
  --input "$RESULTS_DIR/combined.json" \
  --save-dir "$RESULTS_DIR" \
  --no-show

echo ""
echo "=== Benchmark complete ==="
echo "Results saved to:"
echo "  - $RESULTS_DIR/combined.json"
echo "  - $RESULTS_DIR/strong_scaling_speedup.png"
echo "  - $RESULTS_DIR/strong_scaling_efficiency.png"
echo "  - $RESULTS_DIR/time_vs_threads.png"
echo "  - $RESULTS_DIR/comparison_bar.png"
