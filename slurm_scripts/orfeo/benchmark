#!/bin/bash
#SBATCH --nodes=1                   # 1 node
#SBATCH --ntasks=1                  # total MPI tasks across nodes
#SBATCH --ntasks-per-node=1         # 1 MPI task on the node
#SBATCH --cpus-per-task=24          # OpenMP threads per MPI task
#SBATCH --mem=0                     # use all available memory
##SBATCH --partition=EPYC
#SBATCH --partition=THIN
#SBATCH -t 00:20:00                 # 20 minutes
##SBATCH --exclusive                 # Get exclusive access to benchmark
#SBATCH --job-name=self_attention

# Set the executable name
EXEC=./cmhsa.out

# =======================================================
# Set OpenMP environment variables
export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}
export OMP_PLACES=cores
export OMP_PROC_BIND=close
# export OMP_DISPLAY_AFFINITY=TRUE

# Loading necessary module
# module load openMPI/5.0.5

# Set the total number of MPI tasks
# TOTAL_MPI_TASKS=${SLURM_NTASKS}

# Print run information
# echo "Running on a single node with ${TOTAL_MPI_TASKS} MPI tasks."

# Minimal Python venv + requirements
VENV_DIR="${VENV_DIR:-.venv}"
PY_BIN="${PY_BIN:-$(command -v python3 || command -v python)}"
if [ -z "$PY_BIN" ]; then
  echo "Python not found. Load a Python module." >&2
  exit 1
fi
[ -d "$VENV_DIR" ] || "$PY_BIN" -m venv "$VENV_DIR"
# shellcheck disable=SC1090
source "$VENV_DIR/bin/activate"
python -m pip install --upgrade pip

# Pick requirements.txt and install always
REQ_FILE="${REQ_FILE:-$(git rev-parse --show-toplevel 2>/dev/null || pwd)/requirements.txt}"
[ -f "$REQ_FILE" ] || REQ_FILE="requirements.txt"
if [ -f "$REQ_FILE" ]; then
  echo "Installing Python dependencies from $REQ_FILE..."
  pip install -r "$REQ_FILE"
else
  echo "requirements.txt not found; skipping pip install."
fi

source .venv/bin/activate

# =======================================================
# Create results directory
RESULTS_DIR="results"
mkdir -p "$RESULTS_DIR"

echo "=== Starting benchmark runs ==="
echo "Results will be saved to $RESULTS_DIR/"

# Thread counts to benchmark
THREAD_COUNTS="1 2 8 12 18 24"

# Run benchmarks for each thread count, saving JSON output
for threads in $THREAD_COUNTS; do
  echo ""
  echo ">>> Running benchmark with $threads threads..."
  export OMP_NUM_THREADS=$threads
  make benchmark \
    BENCH_BACKEND=multi \
    BENCH_THREADS=$threads \
    USE_SRUN=1 \
    BENCH_OUTPUT_FILE="$RESULTS_DIR/benchmark_${threads}threads.json"
done

echo ""
echo "=== Merging benchmark results ==="

# Merge all JSON files into combined.json and delete individual files
python3 python_src/merge_results.py \
  "$RESULTS_DIR"/benchmark_*threads.json \
  --output "$RESULTS_DIR/combined.json" \
  --delete-inputs

echo ""
echo "=== Generating scaling plots ==="

# Generate scaling plots from combined results
python3 python_src/plotting/scaling_plot.py \
  --input "$RESULTS_DIR/combined.json" \
  --save-dir "$RESULTS_DIR" \
  --no-show

echo ""
echo "=== Benchmark complete ==="
echo "Results saved to:"
echo "  - $RESULTS_DIR/combined.json"
echo "  - $RESULTS_DIR/strong_scaling_speedup.png"
echo "  - $RESULTS_DIR/strong_scaling_efficiency.png"
echo "  - $RESULTS_DIR/time_vs_threads.png"
echo "  - $RESULTS_DIR/comparison_bar.png"
